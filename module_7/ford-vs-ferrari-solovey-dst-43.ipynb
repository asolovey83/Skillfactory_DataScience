{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Classification","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-28T09:20:07.600626Z","iopub.execute_input":"2021-10-28T09:20:07.600927Z","iopub.status.idle":"2021-10-28T09:20:08.513785Z","shell.execute_reply.started":"2021-10-28T09:20:07.600894Z","shell.execute_reply":"2021-10-28T09:20:08.512753Z"}}},{"cell_type":"markdown","source":"### The main idea of this Kaggle is to take a base model pre-trained on ImageNet and to retrain it on our data for classification problem solution","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:19:54.291719Z","iopub.execute_input":"2021-10-28T09:19:54.29201Z","iopub.status.idle":"2021-10-28T09:20:06.171304Z","shell.execute_reply.started":"2021-10-28T09:19:54.291978Z","shell.execute_reply":"2021-10-28T09:20:06.170107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport pickle\nimport zipfile\nimport csv\nimport cv2\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\n\nimport albumentations as A\n\nfrom tensorflow.keras.models import Model\nfrom keras.models import Sequential\n\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications import EfficientNetB0\n\nfrom tensorflow.keras import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.layers.experimental.preprocessing import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.optimizers.schedules import *\n\n\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n\n#increasing default size of the plots\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-28T09:20:12.892682Z","iopub.execute_input":"2021-10-28T09:20:12.89302Z","iopub.status.idle":"2021-10-28T09:20:21.365833Z","shell.execute_reply.started":"2021-10-28T09:20:12.892985Z","shell.execute_reply":"2021-10-28T09:20:21.363726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Основные настройки","metadata":{}},{"cell_type":"code","source":"# Main Settings\n\nEPOCHS               = 5  # it was defined empirically that 5 epochs is enough for learning\nBATCH_SIZE           = 32 # if the network is big we need to decrease the Batch size, otherwise we`ll run out of memory\nLR                   = 1e-4 # it was defined empirically that this values is the best for learning rate\nVAL_SPLIT            = 0.2 # the share of the validation dataset\nCLASS_NUM            = 10  # number of classes in our problem\nIMG_SIZE             = 224 # default image size\nIMG_CHANNELS         = 3   # RGB has 3 channels\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\" # working directory","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:20:26.169078Z","iopub.execute_input":"2021-10-28T09:20:26.169827Z","iopub.status.idle":"2021-10-28T09:20:26.17752Z","shell.execute_reply.started":"2021-10-28T09:20:26.16979Z","shell.execute_reply":"2021-10-28T09:20:26.176098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(PATH,exist_ok=True)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:20:28.736739Z","iopub.execute_input":"2021-10-28T09:20:28.737702Z","iopub.status.idle":"2021-10-28T09:20:28.74424Z","shell.execute_reply.started":"2021-10-28T09:20:28.737659Z","shell.execute_reply":"2021-10-28T09:20:28.743195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Reading data from the folders\ntrain_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:21:25.569414Z","iopub.execute_input":"2021-10-28T09:21:25.569712Z","iopub.status.idle":"2021-10-28T09:21:25.634047Z","shell.execute_reply.started":"2021-10-28T09:21:25.569679Z","shell.execute_reply":"2021-10-28T09:21:25.633042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T08:38:17.379721Z","iopub.execute_input":"2021-10-28T08:38:17.380022Z","iopub.status.idle":"2021-10-28T08:38:17.407049Z","shell.execute_reply.started":"2021-10-28T08:38:17.379988Z","shell.execute_reply":"2021-10-28T08:38:17.406066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's look at the classes distributions in the training dataset","metadata":{}},{"cell_type":"code","source":"train_df.Category.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:22:20.821108Z","iopub.execute_input":"2021-10-27T15:22:20.821422Z","iopub.status.idle":"2021-10-27T15:22:20.829638Z","shell.execute_reply.started":"2021-10-27T15:22:20.821391Z","shell.execute_reply":"2021-10-27T15:22:20.828881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The training dataset looks pretty balanced","metadata":{}},{"cell_type":"code","source":"train_df.hist(bins=100, figsize=(5,5))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:22:29.840929Z","iopub.execute_input":"2021-10-27T15:22:29.84178Z","iopub.status.idle":"2021-10-27T15:22:30.304286Z","shell.execute_reply.started":"2021-10-27T15:22:29.841715Z","shell.execute_reply":"2021-10-27T15:22:30.303332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzipping the files so that you can see them..\nprint('Unpacking images')\n\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:20:35.830588Z","iopub.execute_input":"2021-10-28T09:20:35.830882Z","iopub.status.idle":"2021-10-28T09:21:04.16805Z","shell.execute_reply.started":"2021-10-28T09:20:35.830851Z","shell.execute_reply":"2021-10-28T09:21:04.166964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Images examples (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-28T08:38:57.54237Z","iopub.execute_input":"2021-10-28T08:38:57.542668Z","iopub.status.idle":"2021-10-28T08:38:58.636776Z","shell.execute_reply.started":"2021-10-28T08:38:57.542638Z","shell.execute_reply":"2021-10-28T08:38:58.635629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Single image\nimage = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"execution":{"iopub.status.busy":"2021-10-28T08:39:01.48793Z","iopub.execute_input":"2021-10-28T08:39:01.488432Z","iopub.status.idle":"2021-10-28T08:39:01.779062Z","shell.execute_reply.started":"2021-10-28T08:39:01.488392Z","shell.execute_reply":"2021-10-28T08:39:01.777987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    \n    validation_split=VAL_SPLIT,\n    # augmentation parameters:\n    horizontal_flip=True,\n    rotation_range=10,\n    shear_range=0.2,\n    brightness_range=(0.8, 1.2),\n)\n\nval_datagen = ImageDataGenerator(    \n    validation_split=VAL_SPLIT,\n)\n\nsub_datagen = ImageDataGenerator(\n    \n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=RANDOM_SEED,\n    subset='training'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=RANDOM_SEED,\n    subset='validation'\n)\n\nsub_generator = sub_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    class_mode=None,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    seed=RANDOM_SEED\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:30:26.636559Z","iopub.execute_input":"2021-10-28T12:30:26.636924Z","iopub.status.idle":"2021-10-28T12:30:27.999858Z","shell.execute_reply.started":"2021-10-28T12:30:26.636889Z","shell.execute_reply":"2021-10-28T12:30:27.997983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing few examples of the images from our dataset\ndef show_first_images(generator, count=6, labels=True, figsize=(20, 5), normalized=False):\n  generator = itertools.islice(generator, count)\n  fig, axes = plt.subplots(nrows=1, ncols=count, figsize=figsize)\n  for batch, ax in zip(generator, axes):\n    if labels:\n      img_batch, labels_batch = batch\n      img, label = img_batch[0], np.argmax(labels_batch[0]) \n    else:\n      img_batch = batch\n      img = img_batch[0]\n    if not normalized:\n      img = img.astype(np.uint8)\n    ax.imshow(img)\n   \n    if labels:\n      ax.set_title(f'Class: {label}')\n  plt.show()\n\nprint('Train:')\nshow_first_images(train_generator)\n\nprint('Val:')\nshow_first_images(val_generator)\n\nprint('Sub:')\nshow_first_images(sub_generator, labels=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T08:39:15.423194Z","iopub.execute_input":"2021-10-28T08:39:15.423835Z","iopub.status.idle":"2021-10-28T08:39:23.791337Z","shell.execute_reply.started":"2021-10-28T08:39:15.423788Z","shell.execute_reply":"2021-10-28T08:39:23.790416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a base model","metadata":{}},{"cell_type":"markdown","source":"#### Let's start with EfficientNetB0 as the base model","metadata":{}},{"cell_type":"code","source":"base_model = EfficientNetB0(weights='imagenet', input_shape=input_shape, include_top=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:24:26.306591Z","iopub.execute_input":"2021-10-27T15:24:26.307158Z","iopub.status.idle":"2021-10-27T15:24:29.181156Z","shell.execute_reply.started":"2021-10-27T15:24:26.307119Z","shell.execute_reply":"2021-10-27T15:24:29.179929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building a model\nmodel = Sequential([\n  base_model, #pre-trained neural network from keras.applications module\n  GlobalMaxPool2D(),\n  Dropout(0.5),\n  Dense(CLASS_NUM, activation='softmax')\n])\n\nmodel.compile(\n    loss=CategoricalCrossentropy(from_logits=True),\n    optimizer=Adam(ExponentialDecay(LR, 100, 0.9)),\n    metrics='accuracy'\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:24:32.934896Z","iopub.execute_input":"2021-10-27T15:24:32.935355Z","iopub.status.idle":"2021-10-27T15:24:33.574281Z","shell.execute_reply.started":"2021-10-27T15:24:32.935302Z","shell.execute_reply":"2021-10-27T15:24:33.573311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training model\nmodel.fit(train_generator, validation_data=val_generator, epochs=5, callbacks=[history])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:41:42.399114Z","iopub.execute_input":"2021-10-26T16:41:42.399691Z","iopub.status.idle":"2021-10-26T18:18:07.366166Z","shell.execute_reply.started":"2021-10-26T16:41:42.399638Z","shell.execute_reply":"2021-10-26T18:18:07.365296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let`s show the learning metrics for the model based on EfficientNetB0 base model on the chart\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:18:21.489315Z","iopub.execute_input":"2021-10-26T18:18:21.489738Z","iopub.status.idle":"2021-10-26T18:18:21.925933Z","shell.execute_reply.started":"2021-10-26T18:18:21.489683Z","shell.execute_reply":"2021-10-26T18:18:21.925039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Original model showed 84% accuracy, which resulted in little bit worse score of 83% in Kaggle Competition. As long as this result was far from the TOP, I proceeded with experiment","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"### I tried 5 different augmentation settings in ImageDataGenerator and the one below performed the best","metadata":{}},{"cell_type":"code","source":"# Data Augmentation settings\ntrain_datagen2 = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ntrain_generator2 = train_datagen2.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=0,\n    subset='training'\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:29:47.055416Z","iopub.execute_input":"2021-10-28T12:29:47.055753Z","iopub.status.idle":"2021-10-28T12:29:48.239643Z","shell.execute_reply.started":"2021-10-28T12:29:47.055704Z","shell.execute_reply":"2021-10-28T12:29:48.237816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training a model with one Epoch\nmodel.fit(train_generator2, validation_data=val_generator, epochs=1, callbacks=[history])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:06:43.941863Z","iopub.execute_input":"2021-10-24T11:06:43.942545Z","iopub.status.idle":"2021-10-24T11:12:13.794162Z","shell.execute_reply.started":"2021-10-24T11:06:43.942505Z","shell.execute_reply":"2021-10-24T11:12:13.793365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training a model with 8 Epochs\nmodel.fit(train_generator2, validation_data=val_generator, epochs=EPOCHS, callbacks=[history])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:06:04.299868Z","iopub.execute_input":"2021-10-24T10:06:04.300154Z","iopub.status.idle":"2021-10-24T10:06:10.974458Z","shell.execute_reply.started":"2021-10-24T10:06:04.300123Z","shell.execute_reply":"2021-10-24T10:06:10.971834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The current model showed a good result comparing to the initial model without augmentation, accuracy - 83% in Kaggle Competition, however, it's not enough, so we have to continue experiments","metadata":{}},{"cell_type":"markdown","source":"### Augmentation using albumentations library","metadata":{}},{"cell_type":"markdown","source":"#### I must mention that I tried up to 10 different augmentations with Albumentation library, both from best practices and from my own experiments. Neither of them worked well.","metadata":{}},{"cell_type":"code","source":"#installing Albumentations library\n!pip install albumentations -q -U","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:24:01.847569Z","iopub.execute_input":"2021-10-27T15:24:01.847872Z","iopub.status.idle":"2021-10-27T15:24:09.656648Z","shell.execute_reply.started":"2021-10-27T15:24:01.847841Z","shell.execute_reply":"2021-10-27T15:24:09.655341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment(image):\n    image = image.astype(np.uint8)\n    \n    aug = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n        A.OneOf([\n            A.CenterCrop(height=224, width=200),\n            A.CenterCrop(height=200, width=224),\n        ],p=0.5),\n        A.OneOf([\n            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n        ],p=0.5),\n        A.GaussianBlur(p=0.05),\n        A.HueSaturationValue(p=0.5),\n        A.RGBShift(p=0.5),\n        A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n        A.Resize(IMG_SIZE, IMG_SIZE)\n])   \n    \n    return aug(image=image)['image']\n    \n\nalbum_datagen = ImageDataGenerator(\n    preprocessing_function=augment\n)\n\nfor _ in range(3):\n\n    album_generator = album_datagen.flow_from_directory(\n      PATH+'train/',\n      target_size=(IMG_SIZE, IMG_SIZE),\n      batch_size=1,\n      shuffle=True,\n      seed=RANDOM_SEED\n    )  \n    \n    show_first_images(album_generator)    \n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:39:52.171842Z","iopub.execute_input":"2021-10-24T10:39:52.172134Z","iopub.status.idle":"2021-10-24T10:39:57.407509Z","shell.execute_reply.started":"2021-10-24T10:39:52.172102Z","shell.execute_reply":"2021-10-24T10:39:57.406756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training a model\nmodel.fit(album_generator, validation_data=val_generator, epochs=1, callbacks=[history])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:45:53.020739Z","iopub.execute_input":"2021-10-24T10:45:53.021332Z","iopub.status.idle":"2021-10-24T10:47:11.794658Z","shell.execute_reply.started":"2021-10-24T10:45:53.021289Z","shell.execute_reply":"2021-10-24T10:47:11.793456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In general, Albumentation library not only failed to improve the metrics, but it even didn't show any good results. My assumption is, that it is because of the specifics of the images.","metadata":{}},{"cell_type":"markdown","source":"## Fine-tuning","metadata":{}},{"cell_type":"markdown","source":"#### Let's try to apply the fine-tuning technique to improve the result of the initial model","metadata":{}},{"cell_type":"code","source":"# Checking number of layers in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:24:40.567499Z","iopub.execute_input":"2021-10-27T15:24:40.567835Z","iopub.status.idle":"2021-10-27T15:24:40.573429Z","shell.execute_reply.started":"2021-10-27T15:24:40.567801Z","shell.execute_reply":"2021-10-27T15:24:40.572707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = True\n\n# training only half of base model layers\nfine_tune_at = len(base_model.layers)//2\n\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:24:44.134508Z","iopub.execute_input":"2021-10-27T15:24:44.134839Z","iopub.status.idle":"2021-10-27T15:24:44.15036Z","shell.execute_reply.started":"2021-10-27T15:24:44.134807Z","shell.execute_reply":"2021-10-27T15:24:44.149001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check number of trainable layers\nlen(base_model.trainable_variables)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:24:48.390834Z","iopub.execute_input":"2021-10-27T15:24:48.39114Z","iopub.status.idle":"2021-10-27T15:24:48.398723Z","shell.execute_reply.started":"2021-10-27T15:24:48.391108Z","shell.execute_reply":"2021-10-27T15:24:48.397692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a model\nmodel.fit(train_generator2, validation_data=val_generator, epochs=EPOCHS, callbacks=[history])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:20:12.498696Z","iopub.execute_input":"2021-10-24T10:20:12.499319Z","iopub.status.idle":"2021-10-24T10:38:45.793523Z","shell.execute_reply.started":"2021-10-24T10:20:12.499266Z","shell.execute_reply":"2021-10-24T10:38:45.79105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Overall fine-tuned model showed a little bit better result in Kaggle Competition - around 85%, which is not enough though. ","metadata":{}},{"cell_type":"markdown","source":"### Let's try EfficientNetB3 model with different parameters","metadata":{}},{"cell_type":"code","source":"base_model_enb3 = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:36:46.361045Z","iopub.execute_input":"2021-10-28T10:36:46.361776Z","iopub.status.idle":"2021-10-28T10:36:52.090976Z","shell.execute_reply.started":"2021-10-28T10:36:46.361743Z","shell.execute_reply":"2021-10-28T10:36:52.089916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building a model. The layers that I use in this model is the result of extended experiments\nmodel_enb3 = Sequential([\n    base_model_enb3, \n    GlobalAveragePooling2D(),\n    BatchNormalization(),\n    Dropout(0.25),\n    Dense(256,activation='relu'),\n    BatchNormalization(),\n    Dense(CLASS_NUM, activation='softmax')\n])\n\nmodel_enb3.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=ExponentialDecay(\n                  0.0009, decay_steps=100, decay_rate=0.9)),\n              metrics='accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:36:56.69555Z","iopub.execute_input":"2021-10-28T10:36:56.695901Z","iopub.status.idle":"2021-10-28T10:36:58.253Z","shell.execute_reply.started":"2021-10-28T10:36:56.695869Z","shell.execute_reply":"2021-10-28T10:36:58.251969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding callback for saving the model with the best accuracy\ncheckpoint = ModelCheckpoint('best_model_enb3.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:37:21.399196Z","iopub.execute_input":"2021-10-28T10:37:21.400094Z","iopub.status.idle":"2021-10-28T10:37:21.4075Z","shell.execute_reply.started":"2021-10-28T10:37:21.400057Z","shell.execute_reply":"2021-10-28T10:37:21.406114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# An object for storing the model learning metrics\nhistory_enb3 = History()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:37:23.760367Z","iopub.execute_input":"2021-10-28T10:37:23.761282Z","iopub.status.idle":"2021-10-28T10:37:23.766474Z","shell.execute_reply.started":"2021-10-28T10:37:23.761203Z","shell.execute_reply":"2021-10-28T10:37:23.764581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making all the layers of the base model trainable. The model showed its best results with such settings\nbase_model_enb3.trainable = True","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:37:26.588288Z","iopub.execute_input":"2021-10-28T10:37:26.588574Z","iopub.status.idle":"2021-10-28T10:37:26.610023Z","shell.execute_reply.started":"2021-10-28T10:37:26.588545Z","shell.execute_reply":"2021-10-28T10:37:26.608817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a model\nmodel_enb3.fit(train_generator2, validation_data=val_generator, epochs=EPOCHS, callbacks=[history_enb3, checkpoint, earlystop])","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:11:58.66487Z","iopub.execute_input":"2021-10-28T11:11:58.665189Z","iopub.status.idle":"2021-10-28T11:40:53.945297Z","shell.execute_reply.started":"2021-10-28T11:11:58.665157Z","shell.execute_reply":"2021-10-28T11:40:53.944146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let`s show the learning metrics for the model based on EfficientNetB3 base model on the chart\nacc = history_enb3.history['accuracy']\nval_acc = history_enb3.history['val_accuracy']\nloss = history_enb3.history['loss']\nval_loss = history_enb3.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:45:28.249066Z","iopub.execute_input":"2021-10-28T11:45:28.249719Z","iopub.status.idle":"2021-10-28T11:45:28.781246Z","shell.execute_reply.started":"2021-10-28T11:45:28.249687Z","shell.execute_reply":"2021-10-28T11:45:28.780198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the model\nmodel_enb3.save('../working/model_enb3.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:10:26.680628Z","iopub.execute_input":"2021-10-28T11:10:26.680957Z","iopub.status.idle":"2021-10-28T11:10:28.129723Z","shell.execute_reply.started":"2021-10-28T11:10:26.680925Z","shell.execute_reply":"2021-10-28T11:10:28.128756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's try TTA improvement for this model","metadata":{}},{"cell_type":"code","source":"# Applying augmentations for the test data\nsub_datagen_enb3 = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.2, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip = True,  # randomly flip images\n    vertical_flip=False  # randomly flip images\n)\n\nsub_generator_enb3 = sub_datagen_enb3.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    class_mode=None,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    seed=RANDOM_SEED  \n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:45:37.590383Z","iopub.execute_input":"2021-10-28T11:45:37.590657Z","iopub.status.idle":"2021-10-28T11:45:37.670493Z","shell.execute_reply.started":"2021-10-28T11:45:37.590626Z","shell.execute_reply":"2021-10-28T11:45:37.669392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Averaging the results\npredictions_enb3 = []\nfor _ in range(5):\n    predictions_enb3.append(model_enb3.predict(sub_generator_enb3, verbose=1))\n    sub_generator_enb3.reset()\npredictions_enb3 = np.array(predictions_enb3)\npredictions_enb3.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:45:42.674697Z","iopub.execute_input":"2021-10-28T11:45:42.674975Z","iopub.status.idle":"2021-10-28T11:54:52.802807Z","shell.execute_reply.started":"2021-10-28T11:45:42.674943Z","shell.execute_reply":"2021-10-28T11:54:52.80174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions_enb3 = predictions_enb3.mean(axis=0).argmax(axis=-1)\nfinal_predictions_enb3","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:55:05.958158Z","iopub.execute_input":"2021-10-28T11:55:05.958487Z","iopub.status.idle":"2021-10-28T11:55:05.967214Z","shell.execute_reply.started":"2021-10-28T11:55:05.958457Z","shell.execute_reply":"2021-10-28T11:55:05.965807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sumbitting predictions\nsubmission_enb3 = pd.DataFrame({\n    'Id': sub_generator_enb3.filenames,\n    'Category': final_predictions_enb3\n}, columns=['Id', 'Category'])\nsubmission_enb3.to_csv('submission_enb3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T11:55:09.912532Z","iopub.execute_input":"2021-10-28T11:55:09.913549Z","iopub.status.idle":"2021-10-28T11:55:09.939433Z","shell.execute_reply.started":"2021-10-28T11:55:09.913491Z","shell.execute_reply":"2021-10-28T11:55:09.938477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The EfficientNetB3 model with all necessary optimizations showed the best accuracy so far. I've got 95,695% of accuracy on Kaggle Competition, however, this is not even a TOP 100 result. So, let's proceed with experiments","metadata":{}},{"cell_type":"markdown","source":"### Let's try another model - EfficientNetB7","metadata":{}},{"cell_type":"markdown","source":"#### First we need to make some modifications for the model parameters before running this model","metadata":{}},{"cell_type":"code","source":"# Changing BATCH size to 8, to fit into model\ntrain_generator_enb7 = train_datagen2.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=16,\n    class_mode='categorical',\n    shuffle=True,\n    seed=RANDOM_SEED,\n    subset='training'\n)\n\nval_generator_enb7 = val_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=16,\n    class_mode='categorical',\n    shuffle=True,\n    seed=RANDOM_SEED,\n    subset='validation'\n)\n\nsub_generator_enb7 = sub_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    class_mode=None,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=16,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:22:04.662161Z","iopub.execute_input":"2021-10-28T09:22:04.662776Z","iopub.status.idle":"2021-10-28T09:22:06.224107Z","shell.execute_reply.started":"2021-10-28T09:22:04.662741Z","shell.execute_reply":"2021-10-28T09:22:06.223131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_enb7 = EfficientNetB7(weights='imagenet', include_top=False, input_shape=input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:22:09.769212Z","iopub.execute_input":"2021-10-28T09:22:09.769525Z","iopub.status.idle":"2021-10-28T09:22:22.247921Z","shell.execute_reply.started":"2021-10-28T09:22:09.769493Z","shell.execute_reply":"2021-10-28T09:22:22.246858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building a model\nmodel_enb7 = Sequential([\n    base_model_enb7,     \n    GlobalAveragePooling2D(),\n    BatchNormalization(),\n    Dropout(0.25),\n    Dense(256,activation='relu'),\n    BatchNormalization(),\n    Dense(CLASS_NUM, activation='softmax')\n])\n\n\nmodel_enb7.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=ExponentialDecay(\n                  0.0009, decay_steps=100, decay_rate=0.9)),\n              metrics='accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:22:24.081817Z","iopub.execute_input":"2021-10-28T09:22:24.082158Z","iopub.status.idle":"2021-10-28T09:22:26.745064Z","shell.execute_reply.started":"2021-10-28T09:22:24.082126Z","shell.execute_reply":"2021-10-28T09:22:26.74414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding callback for saving the model with the best accuracy\ncheckpoint = ModelCheckpoint('best_model_enb7.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:22:29.577739Z","iopub.execute_input":"2021-10-28T09:22:29.578083Z","iopub.status.idle":"2021-10-28T09:22:29.586133Z","shell.execute_reply.started":"2021-10-28T09:22:29.578021Z","shell.execute_reply":"2021-10-28T09:22:29.585089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The experiments showed that the model performs best if we disable the base model training at all.\nbase_model_enb7.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:22:32.777906Z","iopub.execute_input":"2021-10-28T09:22:32.778208Z","iopub.status.idle":"2021-10-28T09:22:32.81867Z","shell.execute_reply.started":"2021-10-28T09:22:32.778179Z","shell.execute_reply":"2021-10-28T09:22:32.817692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a model\nmodel_enb7.fit(train_generator_enb7, validation_data=val_generator_enb7, epochs=EPOCHS, callbacks=[history_enb7, checkpoint, earlystop])","metadata":{"execution":{"iopub.status.busy":"2021-10-28T09:22:35.983657Z","iopub.execute_input":"2021-10-28T09:22:35.984017Z","iopub.status.idle":"2021-10-28T10:20:27.166307Z","shell.execute_reply.started":"2021-10-28T09:22:35.983985Z","shell.execute_reply":"2021-10-28T10:20:27.163762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let`s show the learning metrics on the chart\nacc = history_enb7.history['accuracy']\nval_acc = history_enb7.history['val_accuracy']\nloss = history_enb7.history['loss']\nval_loss = history_enb7.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:20:32.661405Z","iopub.execute_input":"2021-10-28T10:20:32.661707Z","iopub.status.idle":"2021-10-28T10:20:33.214877Z","shell.execute_reply.started":"2021-10-28T10:20:32.661675Z","shell.execute_reply":"2021-10-28T10:20:33.213835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the model\nmodel_enb7.save('../working/model_enb7.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's try TTA improvement for EfficientNetB7 model","metadata":{}},{"cell_type":"code","source":"sub_datagen_enb7 = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.2, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip = True,  # randomly flip images\n    vertical_flip=False  # randomly flip images\n)\n\nsub_generator_enb7 = sub_datagen_enb7.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    class_mode=None,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=16,\n    shuffle=False,\n    seed=RANDOM_SEED  \n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:20:54.220816Z","iopub.execute_input":"2021-10-28T10:20:54.221139Z","iopub.status.idle":"2021-10-28T10:20:54.302827Z","shell.execute_reply.started":"2021-10-28T10:20:54.221108Z","shell.execute_reply":"2021-10-28T10:20:54.301665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Averaging results\npredictions_enb7 = []\nfor _ in range(5):\n    predictions_enb7.append(model_enb7.predict(sub_generator_enb7, verbose=1))\n    sub_generator_enb7.reset()\npredictions_enb7 = np.array(predictions_enb7)\npredictions_enb7.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:22:04.172435Z","iopub.execute_input":"2021-10-28T10:22:04.172759Z","iopub.status.idle":"2021-10-28T10:33:04.858211Z","shell.execute_reply.started":"2021-10-28T10:22:04.172718Z","shell.execute_reply":"2021-10-28T10:33:04.857255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions_enb7 = predictions_enb7.mean(axis=0).argmax(axis=-1)\nfinal_predictions_enb7","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:33:06.762158Z","iopub.execute_input":"2021-10-28T10:33:06.762509Z","iopub.status.idle":"2021-10-28T10:33:06.771077Z","shell.execute_reply.started":"2021-10-28T10:33:06.762478Z","shell.execute_reply":"2021-10-28T10:33:06.770046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sumbitting predictions\nsubmission_enb7 = pd.DataFrame({\n    'Id': sub_generator_enb7.filenames,\n    'Category': final_predictions_enb7\n}, columns=['Id', 'Category'])\nsubmission_enb7.to_csv('submission_enb7.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T10:33:14.490276Z","iopub.execute_input":"2021-10-28T10:33:14.490903Z","iopub.status.idle":"2021-10-28T10:33:14.519668Z","shell.execute_reply.started":"2021-10-28T10:33:14.490861Z","shell.execute_reply":"2021-10-28T10:33:14.518713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The EfficientNetB7 model with all necessary optimizations showed the best accuracy so far. I've got 95,9% of accuracy on Kaggle Competition, however, this is not even a TOP 100 result. So, let's proceed with experiments","metadata":{}},{"cell_type":"markdown","source":"### Let's try an ansamble of EfficientNetB3 and EfficientNetB7 models","metadata":{}},{"cell_type":"code","source":"# Empirically I came out with the ideal coefficients of 0,5 for both models\npredictions_ans = 0.5*model_enb3.predict(sub_generator_enb3) + 0.5*model_enb7.predict(sub_generator_enb7) \npredictions_ans = predictions_ans.argmax(axis=1)\npredictions_ans","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:16:25.412466Z","iopub.execute_input":"2021-10-28T12:16:25.412786Z","iopub.status.idle":"2021-10-28T12:19:56.950352Z","shell.execute_reply.started":"2021-10-28T12:16:25.412753Z","shell.execute_reply":"2021-10-28T12:19:56.949217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sumbitting predictions\nsubmission_ans = pd.DataFrame({\n    'Id': sub_generator.filenames,\n    'Category': predictions_ans\n}, columns=['Id', 'Category'])\nsubmission_ans.to_csv('submission_ans2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:22:07.661161Z","iopub.execute_input":"2021-10-28T12:22:07.661477Z","iopub.status.idle":"2021-10-28T12:22:07.687602Z","shell.execute_reply.started":"2021-10-28T12:22:07.661446Z","shell.execute_reply":"2021-10-28T12:22:07.686662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The ensemble of two base models EfficientNetB3 and EfficientNetB7 gave the best score that I achieved on Kaggle Competition - 0.96554","metadata":{}},{"cell_type":"markdown","source":"## Let's try another base model, from different family - Xception","metadata":{}},{"cell_type":"code","source":"base_model_x = Xception(weights='imagenet', include_top=False, input_shape = input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:25:19.129848Z","iopub.execute_input":"2021-10-28T12:25:19.130165Z","iopub.status.idle":"2021-10-28T12:25:21.340531Z","shell.execute_reply.started":"2021-10-28T12:25:19.130133Z","shell.execute_reply":"2021-10-28T12:25:21.339503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building a model\nmodel_x = Sequential([\n  base_model_x,\n  GlobalAveragePooling2D(),\n  BatchNormalization(),\n  Dropout(0.25),\n  Dense(256,activation='relu'),\n  BatchNormalization(),\n  Dense(CLASS_NUM, activation='softmax')\n])\n\nmodel_x.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=ExponentialDecay(\n                  0.0009, decay_steps=100, decay_rate=0.9)),\n              metrics='accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:27:21.108802Z","iopub.execute_input":"2021-10-28T12:27:21.109169Z","iopub.status.idle":"2021-10-28T12:27:21.608027Z","shell.execute_reply.started":"2021-10-28T12:27:21.1091Z","shell.execute_reply":"2021-10-28T12:27:21.606999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding callback for saving the model with the best accuracy\ncheckpoint = ModelCheckpoint('best_model_x.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:28:04.523999Z","iopub.execute_input":"2021-10-28T12:28:04.524319Z","iopub.status.idle":"2021-10-28T12:28:04.532954Z","shell.execute_reply.started":"2021-10-28T12:28:04.524287Z","shell.execute_reply":"2021-10-28T12:28:04.530185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# An object for storing learning metrics\nhistory_x = History()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:27:30.122537Z","iopub.execute_input":"2021-10-28T12:27:30.12315Z","iopub.status.idle":"2021-10-28T12:27:30.128829Z","shell.execute_reply.started":"2021-10-28T12:27:30.123103Z","shell.execute_reply":"2021-10-28T12:27:30.127478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a model\nmodel_x.fit(train_generator2, validation_data=val_generator, epochs=EPOCHS, callbacks=[history_x, checkpoint, earlystop])","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:30:49.742654Z","iopub.execute_input":"2021-10-28T12:30:49.742968Z","iopub.status.idle":"2021-10-28T12:58:56.805162Z","shell.execute_reply.started":"2021-10-28T12:30:49.742938Z","shell.execute_reply":"2021-10-28T12:58:56.804207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let`s show the learning metrics on the chart\nacc = history_x.history['accuracy']\nval_acc = history_x.history['val_accuracy']\nloss = history_x.history['loss']\nval_loss = history_x.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:00:46.582631Z","iopub.execute_input":"2021-10-28T13:00:46.583456Z","iopub.status.idle":"2021-10-28T13:00:47.166724Z","shell.execute_reply.started":"2021-10-28T13:00:46.583418Z","shell.execute_reply":"2021-10-28T13:00:47.165183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's try TTA improvement for Xception model","metadata":{}},{"cell_type":"code","source":"sub_datagen_x = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.2, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip = True,  # randomly flip images\n    vertical_flip=False  # randomly flip images\n)\n\nsub_generator_x = sub_datagen_x.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    class_mode=None,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    seed=RANDOM_SEED  \n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:02:59.867025Z","iopub.execute_input":"2021-10-28T13:02:59.867339Z","iopub.status.idle":"2021-10-28T13:02:59.949825Z","shell.execute_reply.started":"2021-10-28T13:02:59.867306Z","shell.execute_reply":"2021-10-28T13:02:59.948569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_x = []\nfor _ in range(5):\n    predictions_x.append(model_x.predict(sub_generator_x, verbose=1))\n    sub_generator_x.reset()\npredictions_x = np.array(predictions_x)\npredictions_x.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:03:50.825486Z","iopub.execute_input":"2021-10-28T13:03:50.82585Z","iopub.status.idle":"2021-10-28T13:12:17.626805Z","shell.execute_reply.started":"2021-10-28T13:03:50.825819Z","shell.execute_reply":"2021-10-28T13:12:17.62582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions_x = predictions_x.mean(axis=0).argmax(axis=-1)\nfinal_predictions_x","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:13:05.416906Z","iopub.execute_input":"2021-10-28T13:13:05.418032Z","iopub.status.idle":"2021-10-28T13:13:05.429697Z","shell.execute_reply.started":"2021-10-28T13:13:05.417992Z","shell.execute_reply":"2021-10-28T13:13:05.428432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_x = pd.DataFrame({\n    'Id': sub_generator_x.filenames,\n    'Category': final_predictions_x\n}, columns=['Id', 'Category'])\nsubmission_x.to_csv('submission_x.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:13:09.355385Z","iopub.execute_input":"2021-10-28T13:13:09.355765Z","iopub.status.idle":"2021-10-28T13:13:09.38626Z","shell.execute_reply.started":"2021-10-28T13:13:09.35572Z","shell.execute_reply":"2021-10-28T13:13:09.385108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xception base model showed also not quite bad result on Kaggle Competition page - 0.95220. It looses to EfficientNet models, however, it is very close. Let`s try to use it in an ensemble as well","metadata":{"_kg_hide-input":false,"_kg_hide-output":true}},{"cell_type":"code","source":"# Empirically I came out with the ideal coefficients for all three models\npredictions_ens = 0.4*model_enb3.predict(sub_generator_enb3) + 0.3*model_enb7.predict(sub_generator_enb7) + 0.3*model_x.predict(sub_generator_x)\npredictions_ens = predictions_ens.argmax(axis=1)\npredictions_ens","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:17:13.277888Z","iopub.execute_input":"2021-10-28T13:17:13.278205Z","iopub.status.idle":"2021-10-28T13:22:32.135251Z","shell.execute_reply.started":"2021-10-28T13:17:13.278173Z","shell.execute_reply":"2021-10-28T13:22:32.134179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submitting predictions\nsubmission_ens = pd.DataFrame({\n    'Id': sub_generator.filenames,\n    'Category': predictions_ens\n}, columns=['Id', 'Category'])\nsubmission_ens.to_csv('submission_ens.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T13:23:07.242185Z","iopub.execute_input":"2021-10-28T13:23:07.242529Z","iopub.status.idle":"2021-10-28T13:23:07.268676Z","shell.execute_reply.started":"2021-10-28T13:23:07.242496Z","shell.execute_reply":"2021-10-28T13:23:07.267654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The ensemble of three models showed a good result in Kaggle Competition with the score of 0.96220? however, it couldn't bet the best result of an ensemble of two EfficientNet models","metadata":{}},{"cell_type":"markdown","source":"**Conclusion:** To get the best score I tried different approaches:\n*  I experimented with different augmentations both using ImageGenerator and Albumnetations library. Unfortunately Albumentations library didn't show any good results\n* I experimented with the Learning Rate, Different Base models and Different Layers Architectures. The best resultws were shown by EfficientNetB3 model, however, the very best result of the score of 0.96554 I achieved with an ensemble of EfficientNetB3 and EfficientNetB7 models\n* TTA helped a lot to improve the score of the models","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}